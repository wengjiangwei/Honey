

# Honey Toolbox

Computer vision toolbox for agile development

<!-- PROJECT SHIELDS -->

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]
[![MIT License][license-shield]][license-url]
[![LinkedIn][linkedin-shield]][linkedin-url]

<!-- PROJECT LOGO -->
<br />

<p align="center">
  <a href="https://github.com/wengjiangwei/Honey/">
    <img src="images/honey.jpg" alt="Logo" width="100" height="100">
  </a>

  <h3 align="center">æ·±åº¦ç½‘ç»œ-æœºå™¨è§†è§‰-å·¥å…·ç®±</h3>
  <p align="center">
    ä¸€ä¸ª"ä¾¿æ·"çš„å¼€å‘æ¨¡æ¿å»å¿«é€Ÿå¼€å§‹ä½ çš„é¡¹ç›®ï¼
    <br />
    <a href="https://github.com/shaojintian/Best_README_template"><strong>æ¢ç´¢æœ¬é¡¹ç›®çš„æ–‡æ¡£ Â»</strong></a>
    <br />
    <br />
    <a href="https://github.com/wengjiangwei/Honey/tree/main/demo">æŸ¥çœ‹Demo</a>
    Â·
    <a href="https://github.com/wengjiangwei/Honey/issues">æŠ¥å‘ŠBug</a>
    Â·
    <a href="https://github.com/wengjiangwei/Honey/issues">æå‡ºæ–°ç‰¹æ€§</a>
  </p>

</p>

## ç›®å½•

- [Honey Toolbox](#honey-toolbox)
  - [ç›®å½•](#ç›®å½•)
    - [ä¸Šæ‰‹æŒ‡å—](#ä¸Šæ‰‹æŒ‡å—)
    - [å¦‚ä½•ä½¿ç”¨](#å¦‚ä½•ä½¿ç”¨)
    - [æ–‡ä»¶ç›®å½•è¯´æ˜](#æ–‡ä»¶ç›®å½•è¯´æ˜)
    - [å¼€å‘çš„æ¶æ„](#å¼€å‘çš„æ¶æ„)
    - [éƒ¨ç½²](#éƒ¨ç½²)
    - [ä½¿ç”¨åˆ°çš„æ¡†æ¶](#ä½¿ç”¨åˆ°çš„æ¡†æ¶)
      - [å¦‚ä½•å‚ä¸å¼€æºé¡¹ç›®](#å¦‚ä½•å‚ä¸å¼€æºé¡¹ç›®)
    - [ç‰ˆæœ¬æ§åˆ¶](#ç‰ˆæœ¬æ§åˆ¶)
    - [ä½œè€…](#ä½œè€…)
    - [ç‰ˆæƒè¯´æ˜](#ç‰ˆæƒè¯´æ˜)

### ä¸Šæ‰‹æŒ‡å—
1. Clone the repo

```sh
git clone https://github.com/wengjiangwei/Honey.git
```
2. Development environment
  
- æ¨èä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ[Conda](https://www.anaconda.com/)

 ```sh
conda create --name Honey_py37 python=3.7
conda activate Honey_py37
```

- è¯·å‚è€ƒ[ç¯å¢ƒé…ç½®æ–‡ä»¶](https://github.com/wengjiangwei/Honey/blob/main/requirement.txt)

 ```sh
pip install -r requirements.txt  -i https://pypi.douban.com/simple/
```
3. å®‰è£…Linuxç«¯çš„latexç¼–è¯‘ç¨‹åº(Maybe work or report an error in doc.generate_pdf(compiler='pdflatex')<strong>)
  ```sh
  sudo apt-get install latexmk
  sudo apt-get install -y texlive-latex-extra
   ```
3. Open SMTP server *e.g. xxx@163.com* 

- [å‚è€ƒé“¾æ¥ï¼Œè¿›è¡Œè®¾ç½®](http://help.163.com/09/1223/14/5R7P6CJ600753VB8.html?servCode=6010376*)
  
### å¦‚ä½•ä½¿ç”¨

1. Train the model with config.yaml file
   ```sh
   cd ./demo
   python train.py --config_path ./demo/config.yaml --email_config ./demo/email_config.yaml
   ```
   ğŸ˜Š æ¨èä½¿ç”¨ç»å¯¹è·¯å¾„
  - Config.yaml  
   ```sh
    ####PDF_information
    project_version: ft_0.1
    developer: wengjiangwei
    ###### project settings #################################
    PDF_path : ../YOLOV5_PDF
    # type=str, default='...', help:training result file path
    root_path : ../Data/A_Rawdata/ft_AutoXML_729
    # type=str, default='...', help:raw image path that save the XML and JPG files.
    anno_path : ../Data/ft_AutoXML_729
    # type=str, default='...', help:annotations and images folder.
    data : ../Data/ft_AutoXML_729/data.yaml
    # type=str, default='...', help:annotations and images folder.
    class_name : ["ftqx", 'ljdl']
    # type=list,  help:detection classes.
    train_val_prec: 0.1
    # type=float,  default=01, help:train and val samples ratio.
    project_path : ../Runs/v5-test
    # same with project      #TODO:ignore the name
    project : ../Runs/v5-test
    # default='./runs/train', help='save to project/name'
    name : 'ft'
    # type=str, default='exp', help='save to project/name'
    imgsz : 640 
    # type=int, default=640, help='train, val image size (pixels'

    ###### yolo settings #################################
    weights : ../Weights/YOLOV5/yolov5l.pt
    # type=str, default='./yolov5s.pt', help='initial weights path'
    cfg : ./libs/det_module/yolov5_v6/models/yolov5l.yaml
    # type=str, default='', help='model.yaml path'
    hyp : ./libs/det_module/yolov5_v6/data/hyps/hyp.scratch-low.yaml
    # type=str, default='./data/hyps/hyp.scratch-low.yaml', help='hyperparameters path'
    epochs : 10 
    # type=int, default=300
    batch-size : 8 
    # type=int, default=16, help='total batch size for all GPUs, -1 for autobatch'
    device : ''
    #  default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu'
    optimizer : 'SGD'
    #  type=str, choices=['SGD', 'Adam', 'AdamW'], default='SGD', help='optimizer'
  ```
- Email_config
```sh
  user: XXXXXX@163.com
  password: XXXXXXXXXXXX
  port: 'smtp.163.com'

  recipient: XXXXX@163.com
  email_title: YOLOv5 training report
  email_content: Please see the attachment file for more information
```
2. Detect the images with detect.yaml file
   ```sh
   python detect.py --config_path ./demo/detect.yaml --email_config ./demo/email_config.yaml
   ```
  Detect config
```sh
#####project name#########################################
project_version: ft_0.1
developer: wengjiangwei
gt_xml_root : ../Data/ft/testSets/anno
target: ['ftqx','ljdl']

###### project settings #################################
weights: ../Runs/v5-test/ft2/weights/best.pt   # model.pt path(s)
source: ../Data/ft/testSets   # file/dir/URL/glob  0 for webcam
data: ../Data/ft_AutoXML_729/data.yaml   # dataset.yaml path
imgsz: [640,640]  # inference size (height  width)

project: ../Runs/v5-test   # save results to project/name
name: detect  # save results to project/name
PDF_path: ../YOLOV5_PDF


save_txt:  true   # save results to *.txt
save_conf:  true   # save confidences in --save-txt labels
save_crop:  true   # save cropped prediction boxes
save_xml :   true  # XML file
save_fusion_images :  true   # save_fusion_images (image  conf and class)
filter_img :  ~ 
###### yolo settings #################################

conf_thres: 0.25   # confidence threshold
iou_thres: 0.45   # NMS IOU threshold
max_det: 1000   # maximum detections per image
device: ''   # cuda device  i.e. 0 or 0 1 2 3 or cpu
view_img:  false   # show results
nosave:  false   # do not save images/videos
classes: ~   # filter by class: --class 0  or --class 0 2 3
agnostic_nms:  false   # class-agnostic NMS
augment:  false   # augmented inference
visualize:  false   # visualize features
update:  false   # update all models
exist_ok:  false   # existing project/name ok  do not increment
line_thickness: 3   # bounding box thickness (pixels)
hide_labels:  false   # hide labels
hide_conf:  false   # hide confidences
half:  false   # use FP16 half-precision inference
dnn:  false  # use OpenCV DNN for ONNX inference
```
### æ–‡ä»¶ç›®å½•è¯´æ˜
eg:

```
â”œâ”€â”€ Data
â”‚Â Â  â”œâ”€â”€ Rawdata (åŸå§‹æ•°æ®é›†)
â”‚Â Â  â”‚Â Â  â””â”€â”€ ft ï¼ˆä¸¾ä¾‹ï¼šæ•°æ®é›†1,å«XML&JPGï¼‰
â”‚Â Â  â”œâ”€â”€ ft ï¼ˆå¯æ ¹æ®Rawdata-ftæ–‡ä»¶å¤¹ï¼Œä»£ç è‡ªåŠ¨ç”Ÿæˆ, it is awesome~, except <testSets folder>ï¼‰
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Annotations
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ images
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ ImageSets
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ JPEGImages
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ labels
â”‚Â Â  â”‚Â Â  â””â”€â”€ testSets (æµ‹è¯•æ•°æ®,å«JPG&)
â”‚Â Â  â”‚Â Â      â””â”€â”€ annotations (çœŸå®XMLæ ‡ç­¾) 
â”œâ”€â”€ Honey
â”‚Â Â  â”œâ”€â”€ demo
â”‚Â Â  â”‚Â Â  â””â”€â”€ wandb (æ—¥å¿—æ–‡ä»¶)
â”‚Â Â  â”œâ”€â”€ libs
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ cls_module
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ models
â”‚Â Â  â”‚Â Â  â””â”€â”€ det_module
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ yolov3 (#TODO yolov3)
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ yolov5_v6 (V6 means target 6.0)
â”‚Â Â  â”‚Â Â      â”‚Â Â  â”œâ”€â”€ data (don't delete!)
â”‚Â Â  â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ hyps
â”‚Â Â  â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ images
â”‚Â Â  â”‚Â Â      â”‚Â Â  â”‚Â Â  â””â”€â”€ scripts
â”‚Â Â  â”‚Â Â      â”‚Â Â  â”œâ”€â”€ models
â”‚Â Â  â”‚Â Â      â”‚Â Â  â””â”€â”€ utils
â”‚Â Â  â”‚Â Â      â””â”€â”€ yolov7 (#TODO yolov7)
â”‚Â Â  â”œâ”€â”€ metrics
â”‚Â Â  â”œâ”€â”€ tools
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ postprocess
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ processing
â”‚Â Â  â””â”€â”€ utils
â”œâ”€â”€ Runs (Project save path)
â”‚Â Â  â”œâ”€â”€ Finished
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ FT_v0
â”‚Â Â  â””â”€â”€ v5-test (For YOLOV5)
â”‚Â Â      â”œâ”€â”€ detect
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ bad_case
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ crops
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ class1
â”‚Â Â      â”‚Â Â  â”‚Â Â  â””â”€â”€ class2
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ detect_fusion_image
â”‚Â Â      â”‚Â Â  â””â”€â”€ labels
â”œâ”€â”€ Weights (pretrained models)
â”‚Â Â  â”œâ”€â”€ Trained_model (Finished model for your works.)
â”‚Â Â  â”œâ”€â”€ YOLOV5
â”‚Â Â  â””â”€â”€ YOLOV7
â””â”€â”€ YOLOV5_PDF (output the report files)

```

### å¼€å‘çš„æ¶æ„ 

è¯·é˜…è¯»[ARCHITECTURE.md](https://github.com/shaojintian/Best_README_template/blob/master/ARCHITECTURE.md) æŸ¥é˜…ä¸ºè¯¥é¡¹ç›®çš„æ¶æ„ã€‚

### éƒ¨ç½²

æš‚æ—  

### ä½¿ç”¨åˆ°çš„æ¡†æ¶

- [YOLOV5](https://github.com/ultralytics/yolov5)

#### å¦‚ä½•å‚ä¸å¼€æºé¡¹ç›®

è´¡çŒ®ä½¿å¼€æºç¤¾åŒºæˆä¸ºä¸€ä¸ªå­¦ä¹ ã€æ¿€åŠ±å’Œåˆ›é€ çš„ç»ä½³åœºæ‰€ã€‚ä½ æ‰€ä½œçš„ä»»ä½•è´¡çŒ®éƒ½æ˜¯**éå¸¸æ„Ÿè°¢**çš„ã€‚
1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### ç‰ˆæœ¬æ§åˆ¶

è¯¥é¡¹ç›®ä½¿ç”¨Gitè¿›è¡Œç‰ˆæœ¬ç®¡ç†ã€‚æ‚¨å¯ä»¥åœ¨repositoryå‚çœ‹å½“å‰å¯ç”¨ç‰ˆæœ¬ã€‚

### ä½œè€…

 *Waynejoneswjw@gmail.com*

### ç‰ˆæƒè¯´æ˜

è¯¥é¡¹ç›®ç­¾ç½²äº†MIT æˆæƒè®¸å¯ï¼Œè¯¦æƒ…è¯·å‚é˜… [LICENSE](https://github.com/wengjiangwei/Honey/blob/main/LICENSE)



